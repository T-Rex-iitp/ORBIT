{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f38df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "\n",
    "print('âœ… Libraries loaded')\n",
    "print(f'XGBoost version: {xgb.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d85468",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = 'data/all_domestic_cleaned.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f'ðŸ“Š Data loaded: {len(df):,}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9270a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def create_features(df):\n",
    " df = df.copy()\n",
    " df['fl_date'] = pd.to_datetime(df['fl_date'])\n",
    " \n",
    " # Time features\n",
    " df['hour'] = df['crs_dep_time'].apply(lambda x: int(str(int(x)).zfill(4)[:2]) if pd.notna(x) else 0)\n",
    " df['month'] = df['fl_date'].dt.month\n",
    " df['day_of_week'] = df['fl_date'].dt.dayofweek\n",
    " df['day_of_month'] = df['fl_date'].dt.day\n",
    " df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    " \n",
    " # Time slot (category)\n",
    " df['time_period'] = pd.cut(df['hour'], bins=[-1, 6, 12, 18, 24], \n",
    " labels=['night', 'morning', 'afternoon', 'evening'])\n",
    " \n",
    " # Peak-season flag\n",
    " df['is_peak_season'] = df['month'].isin([6, 7, 8, 12]).astype(int)\n",
    " \n",
    " return df\n",
    "\n",
    "df = create_features(df)\n",
    "print('âœ… Feature engineering complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccf977a",
   "metadata": {},
   "source": [
    "## 2. Add Historical Delay Statistics by Airline/Airport (Key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29c8998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average delay by airline\n",
    "carrier_delay = df.groupby('op_unique_carrier')['dep_delay'].mean().to_dict()\n",
    "df['carrier_avg_delay'] = df['op_unique_carrier'].map(carrier_delay)\n",
    "\n",
    "# Average delay by origin\n",
    "origin_delay = df.groupby('origin')['dep_delay'].mean().to_dict()\n",
    "df['origin_avg_delay'] = df['origin'].map(origin_delay)\n",
    "\n",
    "# Average delay by time slot\n",
    "hour_delay = df.groupby('hour')['dep_delay'].mean().to_dict()\n",
    "df['hour_avg_delay'] = df['hour'].map(hour_delay)\n",
    "\n",
    "# Average delay by day of week\n",
    "dow_delay = df.groupby('day_of_week')['dep_delay'].mean().to_dict()\n",
    "df['dow_avg_delay'] = df['day_of_week'].map(dow_delay)\n",
    "\n",
    "print('âœ… Added historical-statistics features')\n",
    "print('\\nAverage delay by airline (Top 5):')\n",
    "print(df.groupby('airline_name')['carrier_avg_delay'].first().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a80e9c",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3930528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "feature_columns = [\n",
    " 'op_unique_carrier', 'origin', 'dest',\n",
    " 'hour', 'month', 'day_of_week', 'day_of_month', 'is_weekend',\n",
    " 'time_period', 'is_peak_season',\n",
    " # Statistical features (key)\n",
    " 'carrier_avg_delay', 'origin_avg_delay', 'hour_avg_delay', 'dow_avg_delay'\n",
    "]\n",
    "\n",
    "target = 'dep_delay'\n",
    "\n",
    "# Remove missing values\n",
    "df_clean = df[feature_columns + [target]].dropna()\n",
    "print(f'âœ… Training data: {len(df_clean):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb251b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_cols = ['op_unique_carrier', 'origin', 'dest', 'time_period']\n",
    "\n",
    "for col in categorical_cols:\n",
    " le = LabelEncoder()\n",
    " df_clean[col] = le.fit_transform(df_clean[col])\n",
    " label_encoders[col] = le\n",
    "\n",
    "print('âœ… Label encoding complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee675b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Val/Test split\n",
    "X = df_clean[feature_columns].values\n",
    "y = df_clean[target].values\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.111, random_state=42)\n",
    "\n",
    "print(f'Train: {len(X_train):,} | Val: {len(X_val):,} | Test: {len(X_test):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cae4a2",
   "metadata": {},
   "source": [
    "## 4. Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0900b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost model\n",
    "model = xgb.XGBRegressor(\n",
    " n_estimators=500,\n",
    " max_depth=8,\n",
    " learning_rate=0.05,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " min_child_weight=3,\n",
    " gamma=0.1,\n",
    " reg_alpha=0.1,\n",
    " reg_lambda=1.0,\n",
    " random_state=42,\n",
    " n_jobs=-1\n",
    ")\n",
    "\n",
    "print('ðŸš€ Starting XGBoost training...')\n",
    "\n",
    "# Train with early stopping\n",
    "model.fit(\n",
    " X_train, y_train,\n",
    " eval_set=[(X_val, y_val)],\n",
    " verbose=50\n",
    ")\n",
    "\n",
    "print('\\nâœ… Training complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e294125",
   "metadata": {},
   "source": [
    "## 5. Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79f1bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_val = model.predict(X_val)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print('ðŸ“Š Performance evaluation:\\n')\n",
    "print('Train:')\n",
    "print(f' MAE: {mean_absolute_error(y_train, y_pred_train):.2f} min')\n",
    "print(f' RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_train)):.2f} min')\n",
    "print(f' RÂ²: {r2_score(y_train, y_pred_train):.4f}')\n",
    "\n",
    "print('\\nValidation:')\n",
    "print(f' MAE: {mean_absolute_error(y_val, y_pred_val):.2f} min')\n",
    "print(f' RMSE: {np.sqrt(mean_squared_error(y_val, y_pred_val)):.2f} min')\n",
    "print(f' RÂ²: {r2_score(y_val, y_pred_val):.4f}')\n",
    "\n",
    "print('\\nTest:')\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(f' MAE: {test_mae:.2f} min')\n",
    "print(f' RMSE: {test_rmse:.2f} min')\n",
    "print(f' RÂ²: {test_r2:.4f}')\n",
    "\n",
    "print(f'\\nâœ… Predicted with average error of {test_mae:.1f} min')\n",
    "print(f' (Reference: mean={y_test.mean():.1f} min, std={y_test.std():.1f} min)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496888da",
   "metadata": {},
   "source": [
    "## 6. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6de9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "importance_df = pd.DataFrame({\n",
    " 'feature': feature_columns,\n",
    " 'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['feature'][:15], importance_df['importance'][:15])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 15 Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nðŸ“Š Most important feature:')\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f997373",
   "metadata": {},
   "source": [
    "## 7. Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0174c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs actual\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred_test, alpha=0.3, s=10)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Delay (min)')\n",
    "plt.ylabel('Predicted Delay (min)')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "errors = y_pred_test - y_test\n",
    "plt.hist(errors, bins=50, edgecolor='black')\n",
    "plt.xlabel('Error (min)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Error Distribution')\n",
    "plt.axvline(0, color='red', linestyle='--', lw=2)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean error: {errors.mean():.2f} min')\n",
    "print(f'Error std dev: {errors.std():.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685c2783",
   "metadata": {},
   "source": [
    "## 8. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c1660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model package\n",
    "model_package = {\n",
    " 'model': model,\n",
    " 'label_encoders': label_encoders,\n",
    " 'feature_columns': feature_columns,\n",
    " 'statistics': {\n",
    " 'carrier_delay': carrier_delay,\n",
    " 'origin_delay': origin_delay,\n",
    " 'hour_delay': hour_delay,\n",
    " 'dow_delay': dow_delay\n",
    " },\n",
    " 'test_metrics': {\n",
    " 'mae': test_mae,\n",
    " 'rmse': test_rmse,\n",
    " 'r2': test_r2\n",
    " }\n",
    "}\n",
    "\n",
    "# Save\n",
    "output_path = 'models/xgboost_predictor.pkl'\n",
    "with open(output_path, 'wb') as f:\n",
    " pickle.dump(model_package, f)\n",
    "\n",
    "print(f'âœ… Model saved: {output_path}')\n",
    "print(f'\\nFinal performance: MAE {test_mae:.2f} min, RÂ² {test_r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c35f525",
   "metadata": {},
   "source": [
    "## âœ… Complete!\n",
    "\n",
    "Why XGBoost can outperform deep learning:\n",
    "1. **Use historical statistics**: Average delays by airline/airport -> strong predictive features\n",
    "2. **Interpretable**: Feature importance shows which factors matter\n",
    "3. **Fast training**: Fast even without GPU\n",
    "4. **Proven performance**: Validated in Kaggle and industry"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
